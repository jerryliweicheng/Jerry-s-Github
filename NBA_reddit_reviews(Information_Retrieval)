{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Information Retrieval"
      ],
      "metadata": {
        "id": "0rjY6e-Gagty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required Packages and Libraries \n",
        " - SpaCy\n",
        " - Scikit Learn"
      ],
      "metadata": {
        "id": "sczzq3U4ammm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy0f1Groa26E",
        "outputId": "493dd233-5d2e-44ea-a7dc-d7165ed9705b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-02-08 17:43:33.885727: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.1/en_core_web_lg-3.4.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-lg==3.4.1) (3.4.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.10.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.25.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (6.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.4.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boolean Retrieval Model"
      ],
      "metadata": {
        "id": "Xr93XPkdarHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Condier A, B, C as documents\n",
        "A = \"I go to ASU and work at ASU\"\n",
        "B = \"I work at ASU\"\n",
        "C = \"I study at ASU\"\n",
        "D = \"We applied for a job at UA\"\n",
        "# Query = A user want to search documents related to ASU\n",
        "query_1 = \"ASU\"\n",
        "query_2 = \"work\"\n",
        "query_3 = \"employment\""
      ],
      "metadata": {
        "id": "awO_q26-tGIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search engine based on term-doc incident matrices\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import pandas as pd\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize, binary = True) \n",
        "X = cv.fit_transform([A,B,C,D])\n",
        "df = pd.DataFrame(X.toarray(), columns = cv.get_feature_names_out(), index = [\"A\", \"B\", \"C\", \"D\"])\n",
        "\n",
        "# print term-doc matrix\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paFNbRcQtLe1",
        "outputId": "19e6a8e9-0ae0-45d0-8549-23d282e4b225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   applied  asu  job  study  ua  work\n",
            "A        0    1    0      0   0     1\n",
            "B        0    1    0      0   0     1\n",
            "C        0    1    0      1   0     0\n",
            "D        1    0    1      0   1     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# when the query is \"asu\"\n",
        "print(df[(df[query_1.lower()] == 1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbK_myppYaWC",
        "outputId": "a09bc726-2169-4103-9f4e-ebd790104042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   applied  asu  job  study  ua  work\n",
            "A        0    1    0      0   0     1\n",
            "B        0    1    0      0   0     1\n",
            "C        0    1    0      1   0     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# when the query is \"ASU\"\n",
        "print(df[(df[query_1] == 1)]) \n",
        "# try to be careful about these details that can produce errors \n",
        "# CountVectorizer converts all characters to lowercase before tokenizing by default."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "amsXzamMZHj3",
        "outputId": "1fed49bd-abf9-42b7-9fb0-47065f009cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'ASU'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-eaf9e1ab6a73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# when the query is \"ASU\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# try to be aware of these small factors that can produce errors and possibly bias your results (e.g,. if you have both \"asu\" and \"ASU\" and search for \"ASU\", then results with lower-cased \"ASU\" will not appear)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'ASU'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# when the query consists of mutliple words \"ASU\" and \"work\"\n",
        "print(df[(df[query_1.lower()] == 1) & (df[query_2.lower()] == 1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNGHzDc-Ztet",
        "outputId": "bbdc62cd-421b-45cb-8755-65818b32c41b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   applied  asu  job  study  ua  work\n",
            "A        0    1    0      0   0     1\n",
            "B        0    1    0      0   0     1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ranked Retrieval Model"
      ],
      "metadata": {
        "id": "cExgaVyoavGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Excercise 1 - Query and documents"
      ],
      "metadata": {
        "id": "TVR1Ky_r_AkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "# Possible documents to be retrieved\n",
        "D1 = \"this article discusses cars & trucks\"\n",
        "D2 = \"every information about Amazon.com\"\n",
        "D3 = \"everything about information technology\"\n",
        "# Queries\n",
        "query = \"information about cars and trucks\""
      ],
      "metadata": {
        "id": "vI9SmhuwgeVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TF matrix with log normalization"
      ],
      "metadata": {
        "id": "9bMNIVU-_dnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(token_pattern=r'\\S+', use_idf=False, smooth_idf=False,\n",
        "sublinear_tf=True, norm= None)\n",
        "doc_vec = vectorizer.fit_transform([D1, D2.replace(\",\",\"\"), D3]) \n",
        "# fit your TF  matrix with only the documents (considering how you would apply the system in a real-world context)\n",
        "doc_vec_mat = pd.DataFrame(doc_vec.toarray(), columns =  vectorizer.get_feature_names_out(), index = [\"D1\", \"D2\", \"D3\"])\n",
        "query_vec = vectorizer.transform([query]) \n",
        "# vectorize queries based on the above TF matrix\n",
        "query_vec_mat_logtf = pd.DataFrame(query_vec.toarray(), columns = vectorizer.get_feature_names_out(), index = [\"q1\"])"
      ],
      "metadata": {
        "id": "HxXLGEcHgoH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.DataFrame(cosine_similarity(query_vec_mat_logtf, doc_vec_mat), columns=[\"D1\", \"D2\", \"D3\"], index = [\"logTF query\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4zOn-ijhOzC",
        "outputId": "f91139e8-dbf8-400d-9d9f-ccf57f3d0048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   D1   D2   D3\n",
            "logTF query  0.408248  0.5  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### # TF matrix with log normalization and IDF normalization (TF-IDF)"
      ],
      "metadata": {
        "id": "JemLtOeK_jGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(token_pattern=r'\\S+', use_idf=True, smooth_idf=True, sublinear_tf=True, norm='l2')\n",
        "doc_vec = vectorizer.fit_transform([D1, D2.replace(\",\",\"\"), D3])\n",
        "doc_vec_mat = pd.DataFrame(doc_vec.toarray(), columns = vectorizer.get_feature_names_out(), index = [\"D1\", \"D2\", \"D3\"])\n",
        "query_vec = vectorizer.transform([query])\n",
        "query_vec_mat_tfidf = pd.DataFrame(query_vec.toarray(), columns = vectorizer.get_feature_names_out(), index = [\"q1\"])\n",
        "print(pd.DataFrame(cosine_similarity(query_vec_mat_tfidf, doc_vec_mat), columns=[\"D1\", \"D2\", \"D3\"], index = [\"TFIDF query\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcuVNMSkg9D9",
        "outputId": "b1edff47-3092-4929-996f-8e03db96f550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   D1        D2        D3\n",
            "TFIDF query  0.459548  0.366447  0.366447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise 2 - Queries and Documents "
      ],
      "metadata": {
        "id": "P1_d_Nje_poI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Possible documents to be retrieved\n",
        "D1 = \"all you’ve ever wanted to know about cars\"\n",
        "D2 = \"information on trucks, information on planes, information on trains\"\n",
        "D3 = \"cops stop red cars more often\"\n",
        "# Queries\n",
        "query_1 = \"Information on cars\"\n",
        "query_2 = \"Information on ships\"\n",
        "query_3 = \"red cars and red trucks\""
      ],
      "metadata": {
        "id": "cMaPZW3JidsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TF matrix without log normalization"
      ],
      "metadata": {
        "id": "5GIbRtPR_vJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(token_pattern=r'\\S+', use_idf=False, smooth_idf=False,\n",
        "sublinear_tf=False, norm=None) \n",
        "# you can also set \"sublinear_tf=True\" to apply idf normalizaiton to log TF\n",
        "doc_vec = vectorizer.fit_transform([D1, D2.replace(\",\",\"\"), D3]) \n",
        "# fit your TF matrix with only the documents (considering how you would apply the system in a real-world context)\n",
        "doc_vec_mat = pd.DataFrame(doc_vec.toarray(), columns = \n",
        "vectorizer.get_feature_names_out(), index = [\"D1\", \"D2\", \"D3\"])\n",
        "print(doc_vec_mat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RebImkVD8lx0",
        "outputId": "841b3b84-14f0-43e7-ff78-957a6c1f9081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    about  all  cars  cops  ever  information  know  more  often   on  planes  \\\n",
            "D1    1.0  1.0   1.0   0.0   1.0          0.0   1.0   0.0    0.0  0.0     0.0   \n",
            "D2    0.0  0.0   0.0   0.0   0.0          3.0   0.0   0.0    0.0  3.0     1.0   \n",
            "D3    0.0  0.0   1.0   1.0   0.0          0.0   0.0   1.0    1.0  0.0     0.0   \n",
            "\n",
            "    red  stop   to  trains  trucks  wanted  you’ve  \n",
            "D1  0.0   0.0  1.0     0.0     0.0     1.0     1.0  \n",
            "D2  0.0   0.0  0.0     1.0     1.0     0.0     0.0  \n",
            "D3  1.0   1.0  0.0     0.0     0.0     0.0     0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_vec = vectorizer.transform([query_1, query_2, query_3]) \n",
        "# vectorize queries based on the above TF matrix \n",
        "query_vec_mat = pd.DataFrame(query_vec.toarray(), columns = vectorizer.get_feature_names_out(), index = [\"q1\", \"q2\", \"q3\"])\n",
        "print(query_vec_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIOSQze48zDf",
        "outputId": "ffaa3890-353b-4882-8eda-6d451ac3aade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    about  all  cars  cops  ever  information  know  more  often   on  planes  \\\n",
            "q1    0.0  0.0   1.0   0.0   0.0          1.0   0.0   0.0    0.0  1.0     0.0   \n",
            "q2    0.0  0.0   0.0   0.0   0.0          1.0   0.0   0.0    0.0  1.0     0.0   \n",
            "q3    0.0  0.0   1.0   0.0   0.0          0.0   0.0   0.0    0.0  0.0     0.0   \n",
            "\n",
            "    red  stop   to  trains  trucks  wanted  you’ve  \n",
            "q1  0.0   0.0  0.0     0.0     0.0     0.0     0.0  \n",
            "q2  0.0   0.0  0.0     0.0     0.0     0.0     0.0  \n",
            "q3  2.0   0.0  0.0     0.0     1.0     0.0     0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the similarities between q1 and all the documents\n",
        "print(\"similarity between q1 and D1:\", cosine_similarity(query_vec_mat.loc[[\"q1\"]],\n",
        "doc_vec_mat.loc[[\"D1\"]])[0], \"\\n\", \\\n",
        "\"similarity between q1 and D2:\", cosine_similarity(query_vec_mat.loc[[\"q1\"]],\n",
        "doc_vec_mat.loc[[\"D2\"]])[0], \"\\n\", \\\n",
        "\"similarity between q1 and D3:\", cosine_similarity(query_vec_mat.loc[[\"q1\"]],\n",
        "doc_vec_mat.loc[[\"D3\"]])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loSy3qek897_",
        "outputId": "a9bc3f2e-50c3-4761-9ab3-bce939bc967b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity between q1 and D1: [0.20412415] \n",
            " similarity between q1 and D2: [0.75592895] \n",
            " similarity between q1 and D3: [0.23570226]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "any problems? \n",
        "\n",
        "- the word \"information\" in the query dominates the results; \n",
        "\n",
        "- D3 more similar than D1? > semantics not considered"
      ],
      "metadata": {
        "id": "5TGhONiJ__ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the similarities between q2 and all the documents\n",
        "print(\"similarity between q2 and D1:\", cosine_similarity(query_vec_mat.loc[[\"q2\"]],\n",
        "doc_vec_mat.loc[[\"D1\"]])[0], \"\\n\",\\\n",
        "\"similarity between q2 and D2:\", cosine_similarity(query_vec_mat.loc[[\"q2\"]],\n",
        "doc_vec_mat.loc[[\"D2\"]])[0], \"\\n\",\\\n",
        "\"similarity between q2 and D3:\", cosine_similarity(query_vec_mat.loc[[\"q2\"]],\n",
        "doc_vec_mat.loc[[\"D3\"]])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRMX6WMl9cJw",
        "outputId": "dd6d6d94-6929-46a9-9e41-4cfefad12dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity between q2 and D1: [0.] \n",
            " similarity between q2 and D2: [0.9258201] \n",
            " similarity between q2 and D3: [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " - we should produce 0 results since there is no document related to \"ships\" in our database\n",
        " - it is good that D1 and D3 are not retrieved but it turns out that our system interpreted D2 to be highly relevant to q2"
      ],
      "metadata": {
        "id": "302ffaRPAJkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the similarities between q3 and all the documents\n",
        "print(\"similarity between q3 and D1:\",cosine_similarity(query_vec_mat.loc[[\"q3\"]], \n",
        "doc_vec_mat.loc[[\"D1\"]])[0], \"\\n\", \\\n",
        "\"similarity between q3 and D2:\",cosine_similarity(query_vec_mat.loc[[\"q3\"]], \n",
        "doc_vec_mat.loc[[\"D2\"]])[0], \"\\n\", \\\n",
        "\"similarity between q3 and D3:\",cosine_similarity(query_vec_mat.loc[[\"q3\"]], \n",
        "doc_vec_mat.loc[[\"D3\"]])[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ5I1Iiw9zM0",
        "outputId": "f351747c-048b-4bb4-b7c8-5a34162fff47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity between q3 and D1: [0.14433757] \n",
            " similarity between q3 and D2: [0.08908708] \n",
            " similarity between q3 and D3: [0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " any problems? \n",
        "\n",
        "(i) the word \"red\" in the query dominates the results; \n",
        "\n",
        "(ii) does not put much important on the word \"trucks\" which in fact has a power to distinguish the characteristics of the documents"
      ],
      "metadata": {
        "id": "6RBIY5r9APq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.DataFrame(cosine_similarity(query_vec_mat, doc_vec_mat), columns=[\"D1\", \n",
        "\"D2\", \"D3\"], index = [\"q1\", \"q2\", \"q3\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkaQghfK-ei9",
        "outputId": "8044b9d7-97e4-4a5f-dea9-8de600272209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          D1        D2        D3\n",
            "q1  0.204124  0.755929  0.235702\n",
            "q2  0.000000  0.925820  0.000000\n",
            "q3  0.144338  0.089087  0.500000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### TF matrix with log normalization"
      ],
      "metadata": {
        "id": "_kzziJOTATK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(token_pattern=r'\\S+', use_idf=False, smooth_idf=False,\n",
        "sublinear_tf=True, norm=None)\n",
        "doc_vec = vectorizer.fit_transform([D1, D2.replace(\",\",\"\"), D3])\n",
        "doc_vec_mat = pd.DataFrame(doc_vec.toarray(), columns = \n",
        "vectorizer.get_feature_names_out(), index = [\"D1\", \"D2\", \"D3\"])\n",
        "print(doc_vec_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zUHtpUg-Mkw",
        "outputId": "b8ef45c5-093e-4c30-b3ec-1d363bdfec9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    about  all  cars  cops  ever  information  know  more  often        on  \\\n",
            "D1    1.0  1.0   1.0   0.0   1.0     0.000000   1.0   0.0    0.0  0.000000   \n",
            "D2    0.0  0.0   0.0   0.0   0.0     2.098612   0.0   0.0    0.0  2.098612   \n",
            "D3    0.0  0.0   1.0   1.0   0.0     0.000000   0.0   1.0    1.0  0.000000   \n",
            "\n",
            "    planes  red  stop   to  trains  trucks  wanted  you’ve  \n",
            "D1     0.0  0.0   0.0  1.0     0.0     0.0     1.0     1.0  \n",
            "D2     1.0  0.0   0.0  0.0     1.0     1.0     0.0     0.0  \n",
            "D3     0.0  1.0   1.0  0.0     0.0     0.0     0.0     0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_vec = vectorizer.transform([query_1, query_2, query_3])\n",
        "query_vec_mat = pd.DataFrame(query_vec.toarray(), columns = \n",
        "vectorizer.get_feature_names_out(), index = [\"q1\", \"q2\", \"q3\"])\n",
        "print(query_vec_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obEUFkFU-jYZ",
        "outputId": "30866ad1-8561-4a26-adca-5301e0a68b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    about  all  cars  cops  ever  information  know  more  often   on  planes  \\\n",
            "q1    0.0  0.0   1.0   0.0   0.0          1.0   0.0   0.0    0.0  1.0     0.0   \n",
            "q2    0.0  0.0   0.0   0.0   0.0          1.0   0.0   0.0    0.0  1.0     0.0   \n",
            "q3    0.0  0.0   1.0   0.0   0.0          0.0   0.0   0.0    0.0  0.0     0.0   \n",
            "\n",
            "         red  stop   to  trains  trucks  wanted  you’ve  \n",
            "q1  0.000000   0.0  0.0     0.0     0.0     0.0     0.0  \n",
            "q2  0.000000   0.0  0.0     0.0     0.0     0.0     0.0  \n",
            "q3  1.693147   0.0  0.0     0.0     1.0     0.0     0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cosine similarity table\n",
        "print(pd.DataFrame(cosine_similarity(query_vec_mat, doc_vec_mat), columns=[\"D1\", \n",
        "\"D2\", \"D3\"], index = [\"q1\", \"q2\", \"q3\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRDDKCjU-ntL",
        "outputId": "e72d423b-22d6-4475-df5c-149afb9e6325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          D1        D2        D3\n",
            "q1  0.204124  0.705191  0.235702\n",
            "q2  0.000000  0.863680  0.000000\n",
            "q3  0.160264  0.131913  0.498385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TF matrix with IDF normalization (IDF)"
      ],
      "metadata": {
        "id": "g1Qd0kaQAbiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(token_pattern=r'\\S+', use_idf=True, smooth_idf=False, sublinear_tf=False, norm=None)\n",
        "doc_vec = vectorizer.fit_transform([D1, D2.replace(\",\",\"\"), D3])\n",
        "doc_vec_mat = pd.DataFrame(doc_vec.toarray(), columns = \n",
        "vectorizer.get_feature_names_out(), index = [\"D1\", \"D2\", \"D3\"])\n",
        "print(doc_vec_mat)\n",
        "query_vec = vectorizer.transform([query_1, query_2, query_3])\n",
        "query_vec_mat = pd.DataFrame(query_vec.toarray(), columns = \n",
        "vectorizer.get_feature_names_out(), index = [\"q1\", \"q2\", \"q3\"])\n",
        "print(query_vec_mat)\n",
        "# cosine similarity table\n",
        "print(pd.DataFrame(cosine_similarity(query_vec_mat, doc_vec_mat), columns=[\"D1\", \n",
        "\"D2\", \"D3\"], index = [\"q1\", \"q2\", \"q3\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7P2EE4G-23l",
        "outputId": "c3652bde-b864-49bc-ad88-39c53e96d24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       about       all      cars      cops      ever  information      know  \\\n",
            "D1  2.098612  2.098612  1.405465  0.000000  2.098612     0.000000  2.098612   \n",
            "D2  0.000000  0.000000  0.000000  0.000000  0.000000     6.295837  0.000000   \n",
            "D3  0.000000  0.000000  1.405465  2.098612  0.000000     0.000000  0.000000   \n",
            "\n",
            "        more     often        on    planes       red      stop        to  \\\n",
            "D1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  2.098612   \n",
            "D2  0.000000  0.000000  6.295837  2.098612  0.000000  0.000000  0.000000   \n",
            "D3  2.098612  2.098612  0.000000  0.000000  2.098612  2.098612  0.000000   \n",
            "\n",
            "      trains    trucks    wanted    you’ve  \n",
            "D1  0.000000  0.000000  2.098612  2.098612  \n",
            "D2  2.098612  2.098612  0.000000  0.000000  \n",
            "D3  0.000000  0.000000  0.000000  0.000000  \n",
            "    about  all      cars  cops  ever  information  know  more  often  \\\n",
            "q1    0.0  0.0  1.405465   0.0   0.0     2.098612   0.0   0.0    0.0   \n",
            "q2    0.0  0.0  0.000000   0.0   0.0     2.098612   0.0   0.0    0.0   \n",
            "q3    0.0  0.0  1.405465   0.0   0.0     0.000000   0.0   0.0    0.0   \n",
            "\n",
            "          on  planes       red  stop   to  trains    trucks  wanted  you’ve  \n",
            "q1  2.098612     0.0  0.000000   0.0  0.0     0.0  0.000000     0.0     0.0  \n",
            "q2  2.098612     0.0  0.000000   0.0  0.0     0.0  0.000000     0.0     0.0  \n",
            "q3  0.000000     0.0  4.197225   0.0  0.0     0.0  2.098612     0.0     0.0  \n",
            "          D1        D2        D3\n",
            "q1  0.105024  0.836740  0.122796\n",
            "q2  0.000000  0.925820  0.000000\n",
            "q3  0.070405  0.093487  0.449391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a search engine on the Reddit data "
      ],
      "metadata": {
        "id": "Xmu91AUuGQ7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCswJ8Z2GYY8",
        "outputId": "869b5c8e-6040-42e8-9708-31b81a906ca2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/gdrive/My Drive/DecisionTree/Reddit.nba/output_nba (2).csv')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "pgC2l6iZGkBT",
        "outputId": "167b6873-2932-4e05-d610-07f146073b61"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         MsgID              Timestamp               Author   ThreadID  \\\n",
              "0    'j7s0r0z'  '2023-02-09 00:08:34'           'REQ52767'  '10xfakf'   \n",
              "1    'j7s0r2r'  '2023-02-09 00:08:35'          'Methzilla'  '10x9u1k'   \n",
              "2    'j7s0rkk'  '2023-02-09 00:08:40'  'unexpectedvillain'  '10xcwdd'   \n",
              "3    'j7s0rnc'  '2023-02-09 00:08:41'  'SuperElection3215'  '10xf5v9'   \n",
              "4    'j7s0rpy'  '2023-02-09 00:08:42'         'OkSteak237'  '10xfc1b'   \n",
              "..         ...                    ...                  ...        ...   \n",
              "108  'j7s1di6'  '2023-02-09 00:12:59'            'ender23'  '10xff6g'   \n",
              "109  'j7s1dkn'  '2023-02-09 00:12:59'             'Vordeo'  '10xff6g'   \n",
              "110  'j7s1do7'  '2023-02-09 00:13:00'     'shaheimjay1121'  '10xe1fj'   \n",
              "111  'j7s1dv2'  '2023-02-09 00:13:03'        'SputnikFace'  '10x5985'   \n",
              "112  'j7s1e68'  '2023-02-09 00:13:06'            'Miscto3'  '10xff6g'   \n",
              "\n",
              "                                           ThreadTitle  \\\n",
              "0    'What would you think about LeBron getting tra...   \n",
              "1    'Kareem Abdul-Jabbar Is Greater Than Any Baske...   \n",
              "2    '[Wojnarowski] ESPN Sources: Three-team trade ...   \n",
              "3    'Mavericks Began Planning Pursuit Of Kyrie Irv...   \n",
              "4    'I was surprised to see that jordan has better...   \n",
              "..                                                 ...   \n",
              "108  '[Charania] “For the Lakers this would be turn...   \n",
              "109  '[Charania] “For the Lakers this would be turn...   \n",
              "110       '3 team deal between Lakers T Wolves & Jazz'   \n",
              "111  'Brooks on getting booed in Memphis: “I get bo...   \n",
              "112  '[Charania] “For the Lakers this would be turn...   \n",
              "\n",
              "                                               MsgBody    ReplyTo  \\\n",
              "0    'The Clippers are above you in the standings lol'  'j7s0kfx'   \n",
              "1    'Hard to say. Then the nba miles on his body s...  'j7rmsby'   \n",
              "2                'Conley stats are 10/7  DLo is 18/6:'  'j7rvies'   \n",
              "3    'They not gonna win anything this year the mav...        '-'   \n",
              "4    'We all know why. People can’t accept greatnes...  'j7s0btu'   \n",
              "..                                                 ...        ...   \n",
              "108  'Only if the jazz and wolves are dumb.  And we...        '-'   \n",
              "109  '> Conley doesn’t have value with that contrac...  'j7s0s7i'   \n",
              "110  'I swear any other team they would say this is...  'j7rwf79'   \n",
              "111                   'Brooks who?!?! Brooks Hatlen!?'        '-'   \n",
              "112  'Conleys contract is partially guaranteed for ...  'j7s0s7i'   \n",
              "\n",
              "                                             Permalink  \n",
              "0    '/r/nba/comments/10xfakf/what_would_you_think_...  \n",
              "1    '/r/nba/comments/10x9u1k/kareem_abduljabbar_is...  \n",
              "2    '/r/nba/comments/10xcwdd/wojnarowski_espn_sour...  \n",
              "3    '/r/nba/comments/10xf5v9/mavericks_began_plann...  \n",
              "4    '/r/nba/comments/10xfc1b/i_was_surprised_to_se...  \n",
              "..                                                 ...  \n",
              "108  '/r/nba/comments/10xff6g/charania_for_the_lake...  \n",
              "109  '/r/nba/comments/10xff6g/charania_for_the_lake...  \n",
              "110  '/r/nba/comments/10xe1fj/3_team_deal_between_l...  \n",
              "111  '/r/nba/comments/10x5985/brooks_on_getting_boo...  \n",
              "112  '/r/nba/comments/10xff6g/charania_for_the_lake...  \n",
              "\n",
              "[113 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-982bad8b-5461-4721-ba39-8957979c8bd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MsgID</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Author</th>\n",
              "      <th>ThreadID</th>\n",
              "      <th>ThreadTitle</th>\n",
              "      <th>MsgBody</th>\n",
              "      <th>ReplyTo</th>\n",
              "      <th>Permalink</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'j7s0r0z'</td>\n",
              "      <td>'2023-02-09 00:08:34'</td>\n",
              "      <td>'REQ52767'</td>\n",
              "      <td>'10xfakf'</td>\n",
              "      <td>'What would you think about LeBron getting tra...</td>\n",
              "      <td>'The Clippers are above you in the standings lol'</td>\n",
              "      <td>'j7s0kfx'</td>\n",
              "      <td>'/r/nba/comments/10xfakf/what_would_you_think_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'j7s0r2r'</td>\n",
              "      <td>'2023-02-09 00:08:35'</td>\n",
              "      <td>'Methzilla'</td>\n",
              "      <td>'10x9u1k'</td>\n",
              "      <td>'Kareem Abdul-Jabbar Is Greater Than Any Baske...</td>\n",
              "      <td>'Hard to say. Then the nba miles on his body s...</td>\n",
              "      <td>'j7rmsby'</td>\n",
              "      <td>'/r/nba/comments/10x9u1k/kareem_abduljabbar_is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'j7s0rkk'</td>\n",
              "      <td>'2023-02-09 00:08:40'</td>\n",
              "      <td>'unexpectedvillain'</td>\n",
              "      <td>'10xcwdd'</td>\n",
              "      <td>'[Wojnarowski] ESPN Sources: Three-team trade ...</td>\n",
              "      <td>'Conley stats are 10/7  DLo is 18/6:'</td>\n",
              "      <td>'j7rvies'</td>\n",
              "      <td>'/r/nba/comments/10xcwdd/wojnarowski_espn_sour...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'j7s0rnc'</td>\n",
              "      <td>'2023-02-09 00:08:41'</td>\n",
              "      <td>'SuperElection3215'</td>\n",
              "      <td>'10xf5v9'</td>\n",
              "      <td>'Mavericks Began Planning Pursuit Of Kyrie Irv...</td>\n",
              "      <td>'They not gonna win anything this year the mav...</td>\n",
              "      <td>'-'</td>\n",
              "      <td>'/r/nba/comments/10xf5v9/mavericks_began_plann...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'j7s0rpy'</td>\n",
              "      <td>'2023-02-09 00:08:42'</td>\n",
              "      <td>'OkSteak237'</td>\n",
              "      <td>'10xfc1b'</td>\n",
              "      <td>'I was surprised to see that jordan has better...</td>\n",
              "      <td>'We all know why. People can’t accept greatnes...</td>\n",
              "      <td>'j7s0btu'</td>\n",
              "      <td>'/r/nba/comments/10xfc1b/i_was_surprised_to_se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>'j7s1di6'</td>\n",
              "      <td>'2023-02-09 00:12:59'</td>\n",
              "      <td>'ender23'</td>\n",
              "      <td>'10xff6g'</td>\n",
              "      <td>'[Charania] “For the Lakers this would be turn...</td>\n",
              "      <td>'Only if the jazz and wolves are dumb.  And we...</td>\n",
              "      <td>'-'</td>\n",
              "      <td>'/r/nba/comments/10xff6g/charania_for_the_lake...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>'j7s1dkn'</td>\n",
              "      <td>'2023-02-09 00:12:59'</td>\n",
              "      <td>'Vordeo'</td>\n",
              "      <td>'10xff6g'</td>\n",
              "      <td>'[Charania] “For the Lakers this would be turn...</td>\n",
              "      <td>'&gt; Conley doesn’t have value with that contrac...</td>\n",
              "      <td>'j7s0s7i'</td>\n",
              "      <td>'/r/nba/comments/10xff6g/charania_for_the_lake...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>'j7s1do7'</td>\n",
              "      <td>'2023-02-09 00:13:00'</td>\n",
              "      <td>'shaheimjay1121'</td>\n",
              "      <td>'10xe1fj'</td>\n",
              "      <td>'3 team deal between Lakers T Wolves &amp; Jazz'</td>\n",
              "      <td>'I swear any other team they would say this is...</td>\n",
              "      <td>'j7rwf79'</td>\n",
              "      <td>'/r/nba/comments/10xe1fj/3_team_deal_between_l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>'j7s1dv2'</td>\n",
              "      <td>'2023-02-09 00:13:03'</td>\n",
              "      <td>'SputnikFace'</td>\n",
              "      <td>'10x5985'</td>\n",
              "      <td>'Brooks on getting booed in Memphis: “I get bo...</td>\n",
              "      <td>'Brooks who?!?! Brooks Hatlen!?'</td>\n",
              "      <td>'-'</td>\n",
              "      <td>'/r/nba/comments/10x5985/brooks_on_getting_boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>'j7s1e68'</td>\n",
              "      <td>'2023-02-09 00:13:06'</td>\n",
              "      <td>'Miscto3'</td>\n",
              "      <td>'10xff6g'</td>\n",
              "      <td>'[Charania] “For the Lakers this would be turn...</td>\n",
              "      <td>'Conleys contract is partially guaranteed for ...</td>\n",
              "      <td>'j7s0s7i'</td>\n",
              "      <td>'/r/nba/comments/10xff6g/charania_for_the_lake...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>113 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-982bad8b-5461-4721-ba39-8957979c8bd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-982bad8b-5461-4721-ba39-8957979c8bd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-982bad8b-5461-4721-ba39-8957979c8bd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "oAdKJ2-sE3r0",
        "outputId": "914004c0-6f41-449a-f96d-630e2b2746dc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       MsgID              Timestamp               Author   ThreadID  \\\n",
              "0  'j7s0r0z'  '2023-02-09 00:08:34'           'REQ52767'  '10xfakf'   \n",
              "1  'j7s0r2r'  '2023-02-09 00:08:35'          'Methzilla'  '10x9u1k'   \n",
              "2  'j7s0rkk'  '2023-02-09 00:08:40'  'unexpectedvillain'  '10xcwdd'   \n",
              "3  'j7s0rnc'  '2023-02-09 00:08:41'  'SuperElection3215'  '10xf5v9'   \n",
              "4  'j7s0rpy'  '2023-02-09 00:08:42'         'OkSteak237'  '10xfc1b'   \n",
              "\n",
              "                                         ThreadTitle  \\\n",
              "0  'What would you think about LeBron getting tra...   \n",
              "1  'Kareem Abdul-Jabbar Is Greater Than Any Baske...   \n",
              "2  '[Wojnarowski] ESPN Sources: Three-team trade ...   \n",
              "3  'Mavericks Began Planning Pursuit Of Kyrie Irv...   \n",
              "4  'I was surprised to see that jordan has better...   \n",
              "\n",
              "                                             MsgBody    ReplyTo  \\\n",
              "0  'The Clippers are above you in the standings lol'  'j7s0kfx'   \n",
              "1  'Hard to say. Then the nba miles on his body s...  'j7rmsby'   \n",
              "2              'Conley stats are 10/7  DLo is 18/6:'  'j7rvies'   \n",
              "3  'They not gonna win anything this year the mav...        '-'   \n",
              "4  'We all know why. People can’t accept greatnes...  'j7s0btu'   \n",
              "\n",
              "                                           Permalink  \n",
              "0  '/r/nba/comments/10xfakf/what_would_you_think_...  \n",
              "1  '/r/nba/comments/10x9u1k/kareem_abduljabbar_is...  \n",
              "2  '/r/nba/comments/10xcwdd/wojnarowski_espn_sour...  \n",
              "3  '/r/nba/comments/10xf5v9/mavericks_began_plann...  \n",
              "4  '/r/nba/comments/10xfc1b/i_was_surprised_to_se...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61a05267-e875-4d26-944c-9599b724aae6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MsgID</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Author</th>\n",
              "      <th>ThreadID</th>\n",
              "      <th>ThreadTitle</th>\n",
              "      <th>MsgBody</th>\n",
              "      <th>ReplyTo</th>\n",
              "      <th>Permalink</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'j7s0r0z'</td>\n",
              "      <td>'2023-02-09 00:08:34'</td>\n",
              "      <td>'REQ52767'</td>\n",
              "      <td>'10xfakf'</td>\n",
              "      <td>'What would you think about LeBron getting tra...</td>\n",
              "      <td>'The Clippers are above you in the standings lol'</td>\n",
              "      <td>'j7s0kfx'</td>\n",
              "      <td>'/r/nba/comments/10xfakf/what_would_you_think_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'j7s0r2r'</td>\n",
              "      <td>'2023-02-09 00:08:35'</td>\n",
              "      <td>'Methzilla'</td>\n",
              "      <td>'10x9u1k'</td>\n",
              "      <td>'Kareem Abdul-Jabbar Is Greater Than Any Baske...</td>\n",
              "      <td>'Hard to say. Then the nba miles on his body s...</td>\n",
              "      <td>'j7rmsby'</td>\n",
              "      <td>'/r/nba/comments/10x9u1k/kareem_abduljabbar_is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'j7s0rkk'</td>\n",
              "      <td>'2023-02-09 00:08:40'</td>\n",
              "      <td>'unexpectedvillain'</td>\n",
              "      <td>'10xcwdd'</td>\n",
              "      <td>'[Wojnarowski] ESPN Sources: Three-team trade ...</td>\n",
              "      <td>'Conley stats are 10/7  DLo is 18/6:'</td>\n",
              "      <td>'j7rvies'</td>\n",
              "      <td>'/r/nba/comments/10xcwdd/wojnarowski_espn_sour...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'j7s0rnc'</td>\n",
              "      <td>'2023-02-09 00:08:41'</td>\n",
              "      <td>'SuperElection3215'</td>\n",
              "      <td>'10xf5v9'</td>\n",
              "      <td>'Mavericks Began Planning Pursuit Of Kyrie Irv...</td>\n",
              "      <td>'They not gonna win anything this year the mav...</td>\n",
              "      <td>'-'</td>\n",
              "      <td>'/r/nba/comments/10xf5v9/mavericks_began_plann...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'j7s0rpy'</td>\n",
              "      <td>'2023-02-09 00:08:42'</td>\n",
              "      <td>'OkSteak237'</td>\n",
              "      <td>'10xfc1b'</td>\n",
              "      <td>'I was surprised to see that jordan has better...</td>\n",
              "      <td>'We all know why. People can’t accept greatnes...</td>\n",
              "      <td>'j7s0btu'</td>\n",
              "      <td>'/r/nba/comments/10xfc1b/i_was_surprised_to_se...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61a05267-e875-4d26-944c-9599b724aae6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61a05267-e875-4d26-944c-9599b724aae6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61a05267-e875-4d26-944c-9599b724aae6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = data['MsgBody']"
      ],
      "metadata": {
        "id": "TpdEiLTdHnR6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy.cli\n",
        "\n",
        "spacy.cli.download(\"en_core_web_lg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwnIEkkBntKZ",
        "outputId": "73de3635-7ef1-47cc-e841-0b70bbc7a7fc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy #load spacy\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "def normalize(review, lowercase, remove_stopwords):\n",
        "    if lowercase:\n",
        "        review = str(review).lower()\n",
        "    doc = nlp(review)\n",
        "    lemmatized = list()\n",
        "    for token in doc:\n",
        "        if not remove_stopwords or (remove_stopwords and not token.is_stop):\n",
        "            lemmatized.append(token.lemma_)\n",
        "    return \" \".join(lemmatized)\n",
        "data['processed'] = data['MsgBody'].apply(normalize, lowercase=True, remove_stopwords=True)"
      ],
      "metadata": {
        "id": "dpcispEGF3Om"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "vectorizer = TfidfVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize, use_idf=True, smooth_idf=True, sublinear_tf=True, norm='l2')\n",
        "tf_idf_mx = vectorizer.fit_transform(data['processed'])\n"
      ],
      "metadata": {
        "id": "_hwX4GTaIgLK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf_idf_mx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AMrEXKAJQR-",
        "outputId": "082e9b78-2ef8-4c7c-e721-3c24e850d1e5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 370)\t0.4840845938990738\n",
            "  (0, 594)\t0.6440838353714465\n",
            "  (0, 121)\t0.5922990114484206\n",
            "  (1, 297)\t0.27927659529701676\n",
            "  (1, 242)\t0.25682254736249954\n",
            "  (1, 394)\t0.24089114681641272\n",
            "  (1, 196)\t0.24089114681641272\n",
            "  (1, 617)\t0.27927659529701676\n",
            "  (1, 586)\t0.47285637992352486\n",
            "  (1, 597)\t0.40786416605406106\n",
            "  (1, 90)\t0.27927659529701676\n",
            "  (1, 402)\t0.27927659529701676\n",
            "  (1, 418)\t0.24089114681641272\n",
            "  (1, 274)\t0.24089114681641272\n",
            "  (2, 33)\t0.41419779369859555\n",
            "  (2, 5)\t0.41419779369859555\n",
            "  (2, 184)\t0.32396615377876425\n",
            "  (2, 34)\t0.3808959801177319\n",
            "  (2, 1)\t0.41419779369859555\n",
            "  (2, 600)\t0.3808959801177319\n",
            "  (2, 138)\t0.3003381410206603\n",
            "  (3, 245)\t0.23118501455544033\n",
            "  (3, 574)\t0.34924265994803483\n",
            "  (3, 76)\t0.32116328788711634\n",
            "  (3, 544)\t0.32116328788711634\n",
            "  :\t:\n",
            "  (112, 469)\t0.18813884085954855\n",
            "  (112, 220)\t0.18813884085954855\n",
            "  (112, 447)\t0.18813884085954855\n",
            "  (112, 54)\t0.18813884085954855\n",
            "  (112, 142)\t0.18813884085954855\n",
            "  (112, 636)\t0.18813884085954855\n",
            "  (112, 168)\t0.18813884085954855\n",
            "  (112, 403)\t0.31854674795516086\n",
            "  (112, 3)\t0.18813884085954855\n",
            "  (112, 263)\t0.18813884085954855\n",
            "  (112, 455)\t0.18813884085954855\n",
            "  (112, 139)\t0.18813884085954855\n",
            "  (112, 449)\t0.17301233680534384\n",
            "  (112, 216)\t0.16227991138021203\n",
            "  (112, 29)\t0.16227991138021203\n",
            "  (112, 625)\t0.12809626599776602\n",
            "  (112, 228)\t0.15395519547710257\n",
            "  (112, 353)\t0.15395519547710257\n",
            "  (112, 363)\t0.11056205242153895\n",
            "  (112, 21)\t0.1414025773859292\n",
            "  (112, 622)\t0.1414025773859292\n",
            "  (112, 80)\t0.2747637744149238\n",
            "  (112, 658)\t0.2747637744149238\n",
            "  (112, 141)\t0.24915237672381846\n",
            "  (112, 688)\t0.24915237672381846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_vec_mat = pd.DataFrame(tf_idf_mx.toarray(), columns = vectorizer.get_feature_names_out(), index = data['MsgID'])\n",
        "print(doc_vec_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szqQqrE1M2MG",
        "outputId": "22ac7af9-ff1b-4260-daf4-fa1c6ba3a01f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  1        10  10th        14   15        18  1992  1st    2  \\\n",
            "MsgID                                                                          \n",
            "'j7s0r0z'  0.000000  0.000000   0.0  0.000000  0.0  0.000000   0.0  0.0  0.0   \n",
            "'j7s0r2r'  0.000000  0.000000   0.0  0.000000  0.0  0.000000   0.0  0.0  0.0   \n",
            "'j7s0rkk'  0.000000  0.414198   0.0  0.000000  0.0  0.414198   0.0  0.0  0.0   \n",
            "'j7s0rnc'  0.000000  0.000000   0.0  0.000000  0.0  0.000000   0.0  0.0  0.0   \n",
            "'j7s0rpy'  0.000000  0.000000   0.0  0.000000  0.0  0.000000   0.0  0.0  0.0   \n",
            "...             ...       ...   ...       ...  ...       ...   ...  ...  ...   \n",
            "'j7s1di6'  0.000000  0.000000   0.0  0.000000  0.0  0.000000   0.0  0.0  0.0   \n",
            "'j7s1dkn'  0.000000  0.000000   0.0  0.000000  0.0  0.000000   0.0  0.0  0.0   \n",
            "'j7s1do7'  0.207356  0.000000   0.0  0.000000  0.0  0.000000   0.0  0.0  0.0   \n",
            "'j7s1dv2'  0.000000  0.000000   0.0  0.000000  0.0  0.000000   0.0  0.0  0.0   \n",
            "'j7s1e68'  0.000000  0.000000   0.0  0.188139  0.0  0.000000   0.0  0.0  0.0   \n",
            "\n",
            "            20  ...  work  worth     wrong  www    y  yea  yeah      year  \\\n",
            "MsgID           ...                                                         \n",
            "'j7s0r0z'  0.0  ...   0.0    0.0  0.000000  0.0  0.0  0.0   0.0  0.000000   \n",
            "'j7s0r2r'  0.0  ...   0.0    0.0  0.000000  0.0  0.0  0.0   0.0  0.000000   \n",
            "'j7s0rkk'  0.0  ...   0.0    0.0  0.000000  0.0  0.0  0.0   0.0  0.000000   \n",
            "'j7s0rnc'  0.0  ...   0.0    0.0  0.000000  0.0  0.0  0.0   0.0  0.273161   \n",
            "'j7s0rpy'  0.0  ...   0.0    0.0  0.450508  0.0  0.0  0.0   0.0  0.000000   \n",
            "...        ...  ...   ...    ...       ...  ...  ...  ...   ...       ...   \n",
            "'j7s1di6'  0.0  ...   0.0    0.0  0.000000  0.0  0.0  0.0   0.0  0.000000   \n",
            "'j7s1dkn'  0.0  ...   0.0    0.0  0.000000  0.0  0.0  0.0   0.0  0.000000   \n",
            "'j7s1do7'  0.0  ...   0.0    0.0  0.000000  0.0  0.0  0.0   0.0  0.000000   \n",
            "'j7s1dv2'  0.0  ...   0.0    0.0  0.000000  0.0  0.0  0.0   0.0  0.000000   \n",
            "'j7s1e68'  0.0  ...   0.0    0.0  0.000000  0.0  0.0  0.0   0.0  0.249152   \n",
            "\n",
            "           yes   yr  \n",
            "MsgID                \n",
            "'j7s0r0z'  0.0  0.0  \n",
            "'j7s0r2r'  0.0  0.0  \n",
            "'j7s0rkk'  0.0  0.0  \n",
            "'j7s0rnc'  0.0  0.0  \n",
            "'j7s0rpy'  0.0  0.0  \n",
            "...        ...  ...  \n",
            "'j7s1di6'  0.0  0.0  \n",
            "'j7s1dkn'  0.0  0.0  \n",
            "'j7s1do7'  0.0  0.0  \n",
            "'j7s1dv2'  0.0  0.0  \n",
            "'j7s1e68'  0.0  0.0  \n",
            "\n",
            "[113 rows x 691 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_1 = \"lebron\" \n",
        "query_2 = \"win\"\n",
        "query_3 = 'game'\n",
        "query_vec = vectorizer.transform([query_1, query_2, query_3])\n",
        "query_vec_mat = pd.DataFrame(query_vec.toarray(), columns = vectorizer.get_feature_names_out(), index = [\"q1\", \"q2\", \"q3\"])\n",
        "print(query_vec_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUhE0ZUkNXPs",
        "outputId": "784a2b5d-ce59-4e4d-977e-2a177c1869f5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      1   10  10th   14   15   18  1992  1st    2   20  ...  work  worth  \\\n",
            "q1  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
            "q2  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
            "q3  0.0  0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  ...   0.0    0.0   \n",
            "\n",
            "    wrong  www    y  yea  yeah  year  yes   yr  \n",
            "q1    0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  \n",
            "q2    0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  \n",
            "q3    0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  \n",
            "\n",
            "[3 rows x 691 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "YmWIzbqGsiz0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(cosine_similarity(doc_vec_mat, query_vec_mat), columns=[\"Q1\", \n",
        "\"Q2\", \"Q3\"], index = data['MsgBody'])\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXiXi62CN9aY",
        "outputId": "deceaa0d-b9e8-4ac9-d0bb-e786f7624d93"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                     Q1        Q2        Q3\n",
            "MsgBody                                                                    \n",
            "'The Clippers are above you in the standings lol'   0.0  0.000000  0.000000\n",
            "'Hard to say. Then the nba miles on his body st...  0.0  0.000000  0.000000\n",
            "'Conley stats are 10/7  DLo is 18/6:'               0.0  0.000000  0.000000\n",
            "'They not gonna win anything this year the mavs...  0.0  0.273161  0.231185\n",
            "'We all know why. People can’t accept greatness...  0.0  0.000000  0.000000\n",
            "...                                                 ...       ...       ...\n",
            "'Only if the jazz and wolves are dumb.  And we ...  0.0  0.000000  0.000000\n",
            "'> Conley doesn’t have value with that contract...  0.0  0.000000  0.226016\n",
            "'I swear any other team they would say this isn...  0.0  0.000000  0.000000\n",
            "'Brooks who?!?! Brooks Hatlen!?'                    0.0  0.000000  0.000000\n",
            "'Conleys contract is partially guaranteed for 1...  0.0  0.000000  0.000000\n",
            "\n",
            "[113 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.sort_values(by=\"Q2\", ascending=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "l6pQ_3DNRhn_",
        "outputId": "a46ea6f1-b92b-4b09-93ba-6447cb478fa6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                          Q1        Q2  \\\n",
              "MsgBody                                                                  \n",
              "'Kyrie one of the best finishers around the rim...  0.000000  0.298026   \n",
              "'They not gonna win anything this year the mavs...  0.000000  0.273161   \n",
              "'KD ruined his own legacy by partnering with su...  0.000000  0.268205   \n",
              "'Celtics starters tonight:  - Blake Griffin - G...  0.000000  0.139701   \n",
              "'This is why the total points record is kinda c...  0.176248  0.079669   \n",
              "...                                                      ...       ...   \n",
              "'Lol a second?  Thats insane.'                      0.000000  0.000000   \n",
              "'I’ll happily oblige and boo you since you’ve m...  0.000000  0.000000   \n",
              "'Neto career high incoming'                         0.000000  0.000000   \n",
              "'Ok apparently Im a heretic for posting this fo...  0.000000  0.000000   \n",
              "'Conleys contract is partially guaranteed for 1...  0.000000  0.000000   \n",
              "\n",
              "                                                          Q3  \n",
              "MsgBody                                                       \n",
              "'Kyrie one of the best finishers around the rim...  0.090348  \n",
              "'They not gonna win anything this year the mavs...  0.231185  \n",
              "'KD ruined his own legacy by partnering with su...  0.000000  \n",
              "'Celtics starters tonight:  - Blake Griffin - G...  0.000000  \n",
              "'This is why the total points record is kinda c...  0.160899  \n",
              "...                                                      ...  \n",
              "'Lol a second?  Thats insane.'                      0.000000  \n",
              "'I’ll happily oblige and boo you since you’ve m...  0.000000  \n",
              "'Neto career high incoming'                         0.000000  \n",
              "'Ok apparently Im a heretic for posting this fo...  0.000000  \n",
              "'Conleys contract is partially guaranteed for 1...  0.000000  \n",
              "\n",
              "[113 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ce8324f-aa43-4f41-bf22-9d056ffcfd26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MsgBody</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>'Kyrie one of the best finishers around the rim ever. One of the best clutch scorers and performed under pressure in the playoffs. Had the best handles in the league when they won. Win MVP of all star game 2014.  Love best rebounder and one of the best outlet passers in the league when they won.  Wade best scorer in the league when they won.  AD was the best PF and small ball center when they won. He gets injured but he didnt when they won a championship.  I have to bring up your comment on Bosh acting like he was just some all-star role player.  Check his career stats. A lot of people felt he should have been in top 75. Guys was a franchise number 1 for almost a decade before Mia.'</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.298026</td>\n",
              "      <td>0.090348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'They not gonna win anything this year the mavs squad around them is too weak for a deep run. But they gonna ball out and be showtime every game'</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.273161</td>\n",
              "      <td>0.231185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'KD ruined his own legacy by partnering with such a shithead when he could’ve won 4 championships right now with the warriors.'</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.268205</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'Celtics starters tonight:  - Blake Griffin - Grant Williams - Jayson Tatum - Jaylen Brown - Derrick White  76ers starters:  - Joel Embiid - P.J. Tucker - Tobias Harris - DeAnthony Melton - James Harden  Sixers should win this with the Cs missing 3 starters'</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.139701</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'This is why the total points record is kinda corny.   Is emmitt the greatest RB of all time? Of course not and nobody is seriously going to debate it.   Jordan went to college for 3 years retired for 2 seasons in the middle of two 3peats and then retired again at like 36 for a few years.   He still scored like 32k points. If you look at total points per season lebrons top season would be Jordans 10th. Jordan play all 82 games more than half the seasons he played. LeBron has done it once in 20 seasons. LeBron managed his games and minutes to be able to compete at a higher level longer. Jordan worked like a psychopath to win as many titles as he could as fast as he could. Jordan played every game after he came back from baseball and 3 peated again. He literally didnt miss one game over 3 seasons.   LeBron is insane but anyone that watched both players throughout their entire careers will tell you Jordan was better and its not even really close. Jordan is the greatest scorer in NBA history. Theres a damn good argument that he is a top 3 defender at SG. His 86-87 season is one that rivals wilts stuff. DPOY and averaged fucking 37 PPG 😂'</th>\n",
              "      <td>0.176248</td>\n",
              "      <td>0.079669</td>\n",
              "      <td>0.160899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'Lol a second?  Thats insane.'</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'I’ll happily oblige and boo you since you’ve made it clear to everyone that you care waaaaaaay too much about what everyone thinks. People who don’t care don’t respond. lol'</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'Neto career high incoming'</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'Ok apparently Im a heretic for posting this for fun but maybe him leaving for the Clips a while from now is more realistic.'</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'Conleys contract is partially guaranteed for 14 million next year its def a tradable contract. Still I think you could get more for Beasley and Vando. Beasley is expiring with a team option and Vando has another year of control at 4.3 million. I feel like all this is just Ainge getting the league to open their eyes and get the phones rumbling'</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>113 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ce8324f-aa43-4f41-bf22-9d056ffcfd26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ce8324f-aa43-4f41-bf22-9d056ffcfd26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ce8324f-aa43-4f41-bf22-9d056ffcfd26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}